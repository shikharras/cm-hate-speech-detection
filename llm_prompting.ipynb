{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import together\n",
    "from time import sleep\n",
    "import re\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dprint(s, debug):\n",
    "    if debug:\n",
    "        print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: find your API key here\n",
    "# https://api.together.xyz/settings/api-keys\n",
    "YOUR_API_KEY = '5a70c1d03697cbf9d7a2c4595ffa8f892bc25311ee89de4dceda77eefb228a84'\n",
    "together.api_key = YOUR_API_KEY\n",
    "\n",
    "def call_together_api(prompt, student_configs, pre_processing, post_processing, model='togethercomputer/llama-2-70b', debug=False):\n",
    "    prompt = pre_processing(prompt)\n",
    "    output = together.Complete.create(\n",
    "    prompt = prompt,\n",
    "    model = model, \n",
    "    **student_configs\n",
    "    )\n",
    "    dprint('*****prompt*****', debug)\n",
    "    dprint(prompt, debug)\n",
    "    dprint('*****result*****', debug)\n",
    "    res = output['output']['choices'][0]['text']\n",
    "    dprint(res, debug)\n",
    "    dprint('*****output*****', debug)\n",
    "    labels_only = post_processing(res)\n",
    "    dprint('POST PROCESSED', debug)\n",
    "    dprint(labels_only, debug)\n",
    "    dprint('=========', debug)\n",
    "    return labels_only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = [\n",
    "    'togethercomputer/llama-2-7b', #LLaMa-2-7B\n",
    "    'togethercomputer/llama-2-13b', #LLaMa-2-13B\n",
    "    'togethercomputer/llama-2-70b', #LLaMa-2-70B\n",
    "    'togethercomputer/llama-2-70b-chat', #LLaMa-2-70B-Chat\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_df(topn = 10):\n",
    "    train_df = pd.read_csv('./data/splits/train.csv')\n",
    "    return train_df[:topn]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_set():\n",
    "    test_df = pd.read_csv('./data/splits/test.csv')\n",
    "    return test_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_eval_df(topn = 5):\n",
    "    eval_df = pd.read_csv('./data/splits/val.csv')\n",
    "    return eval_df.sample(topn)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_range(df, prompt_configs, prompt_prefix, examples, prompt_suffix,\n",
    "               pre_processing=lambda x:x, post_processing=lambda y:y,\n",
    "               model='togethercomputer/llama-2-70b', debug=False):\n",
    "    tweet_idx = []\n",
    "    answers = []\n",
    "    model_responses = []\n",
    "    corrected_model_responses = []\n",
    "    tweet_txt_list = []\n",
    "    ap_text = \"\"\n",
    "    for idx, row in tqdm(df.iterrows()):\n",
    "        tweet_idx.append(row['id'])\n",
    "        fixed_prompt = row['tweet_text'] + \"\\n\"\n",
    "        tweet_txt_list.append(row['tweet_text'])\n",
    "        fixed_prompt = pre_processing(fixed_prompt)\n",
    "        prompt = prompt_prefix + examples + fixed_prompt + prompt_suffix\n",
    "        answer = row['offense']\n",
    "        answers.append(answer)\n",
    "        model_response = call_together_api(prompt, prompt_configs, pre_processing, lambda y:y, model=model, debug=debug)\n",
    "        corrected_model_response = post_processing(model_response)\n",
    "        corrected_model_responses.append(corrected_model_response)\n",
    "        model_responses.append(model_response)\n",
    "        sleep(1)\n",
    "    df = pd.DataFrame({'tweet_idx': tweet_idx, 'tweet_text': tweet_txt_list, 'model_responses': model_responses, 'corrected_model_responses':corrected_model_responses, 'offense': answers})\n",
    "    return df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zero Shot Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_prefix_zs = \\\n",
    "'''Offensive speech focuses on the potentially hurtful effect of the tweet content on a given target. This category of text often contains offensive words such as sarcastic remarks, insults, slanders, and slurs.\n",
    "Based on above definition, classify the following Hinglish tweet into offensive speech or not. \n",
    "Your output should only be either \"OFF\" for offensive, or \"NOT\" for not offensive.\n",
    "'''\n",
    "prompt_examples_zs = \"Input Tweet: \"\n",
    "prompt_suffix_zs = \"Output: \"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_string: '@user tweet'\n",
    "def your_pre_processing_zs(input_string):\n",
    "    return re.sub(r\"@user\",\"\", input_string).strip()\n",
    "\n",
    "def your_post_processing_zs(output_string):\n",
    "    # using regular expression to find the first consecutive digits in the returned string\n",
    "    if output_string.strip().lower()[:3]=='off':\n",
    "        return 1\n",
    "    elif output_string.strip().lower()[:3]=='not':\n",
    "        return 0\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "togethercomputer/llama-2-70b-chat\n"
     ]
    }
   ],
   "source": [
    "prompt_config_zs = {'max_tokens': 3,\n",
    "                'temperature': 0.4,\n",
    "                'top_k': 50,\n",
    "                'top_p': 0.7,\n",
    "                'repetition_penalty': 1,\n",
    "                'stop': []}\n",
    "\n",
    "model = 'togethercomputer/llama-2-70b-chat'\n",
    "print(model)\n",
    "\n",
    "eval_df = get_eval_df(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [01:25,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    tweet_idx                                         tweet_text  \\\n",
      "0         632  #Demonetisation A dream of many executed by #M...   \n",
      "1      178287  @user Aren't honourable Judges aware about pre...   \n",
      "2       79887  @user Muslims harassing Hindus in UK, USA and ...   \n",
      "3        1062  @user Where are when 2015 floods  came ‚Ä¶..when...   \n",
      "4       34391  INDIAN ARMY CARRIES OUT LARGE FIELD TRAINING E...   \n",
      "5       65790  is covid-19 still a thing of have they deemed ...   \n",
      "6      169445  Cricket gods should honour and bless Sikander ...   \n",
      "7       26597  @user @user Your tweet wasn't worded properly ...   \n",
      "8       15249  @user @user @user You're just flat wrong about...   \n",
      "9       75929  @user @user Yes, but the data says whole hindi...   \n",
      "10      59974  @user Comparison is lame. Biden reduced defici...   \n",
      "11     181862  @user @user \\nIt's a mockery of the system!\\nA...   \n",
      "12      30342  @user Big salute no sir  \\nBig big salute Indi...   \n",
      "13     213424  @user In 1966, Golwalkar, in his book titled B...   \n",
      "14     142273  Maybe my tweets are not liked today but in fut...   \n",
      "15      22793  @user @user @user I wear 'secularism ka tilak' üòåüòå   \n",
      "16     124690  @user These girls deserve this because when pe...   \n",
      "17     116398    @user Try it and thank me later\\nMunci a SBRSüòÇüòÇ   \n",
      "18      49958  60 startups registered with #ISRO since unlock...   \n",
      "19     197440  @user @user @user Note pe to Gandhiji bhi bane...   \n",
      "20     192426  @user Congress is not a political party.. It i...   \n",
      "21     188771  @user @user @user Indira Gandhi imposed an eme...   \n",
      "22      45499  @user @user @user @user @user Compare the numb...   \n",
      "23       1158  @user Indians should not laugh at this. Demone...   \n",
      "24        290  @user @user @user @user @user Not sure if you‚Äô...   \n",
      "25      34353  @user If I remember right , Pakistani media us...   \n",
      "26     165124  @user @user @user @user @user Sports authoriti...   \n",
      "27      45580  .......through his foundation, in collaboratio...   \n",
      "28     208740  @user Gandhi and Nehru se nafrat hay..\\nModiji...   \n",
      "29      75920                               @user Is she dalit??   \n",
      "30     154932  @user Rakesh tikait the terrorist of India.\\nI...   \n",
      "31      22804  @user Agreed, deliberate diversion. India neve...   \n",
      "32     178313  @user @user üòÇü§£ 5/6 judges' here and there will...   \n",
      "33     124486  @user Also in the Lataji case, there was no ne...   \n",
      "34     181802  @user He will have access to medical treatment...   \n",
      "35     159896  @user ‡§≤‡§ó‡§§‡§æ ‡§π‡•à ‡§∏‡§∞‡§ï‡§æ‡§∞ ‡§ï‡•ã‡§à ‡§π‡•à ‡§π‡•Ä ‡§®‡§π‡•Ä...‡§á‡§∏‡§™‡•á UAPA ...   \n",
      "36        568  @user Amazing! What about the pending cases wi...   \n",
      "37     165490  Announcing equal pay for both men and women in...   \n",
      "38     159840  SG makes an intervention: This request of hous...   \n",
      "39      71673                        @user ‡§¶‡•á‡§∂ ‡§ï‡•Ä  ‡§â‡§Æ‡•ç‡§Æ‡•Ä‡§¶  @user   \n",
      "40        448  @user Go to any doctors or lawyers, they charg...   \n",
      "41      59932  Today, Louisville Elementary School went into ...   \n",
      "42     129857  #Gujarat | Union Home and Cooperation Minister...   \n",
      "43        892  @user Let's first talk about what Indian Gover...   \n",
      "44     133908  @user Yes, well, you‚Äôre a Marxist. You may not...   \n",
      "45       3808  @user @user So, you‚Äôre saying because people i...   \n",
      "46     164836  Pakistan fans will definitely be praying for I...   \n",
      "47     186613  @user Jo bharose Wale emergency lagye hai wo k...   \n",
      "48      30326  @user @user @user @user @user @user @user @use...   \n",
      "49      17529  #MaritalRape indian supreme court is going to ...   \n",
      "\n",
      "   model_responses  corrected_model_responses  offense  \n",
      "0              NOT                          0        0  \n",
      "1              NOT                          0        1  \n",
      "2             \\n\\n                          0        0  \n",
      "3              NOT                          0        0  \n",
      "4          NOT\\n\\n                          0        0  \n",
      "5              OFF                          1        0  \n",
      "6             \\n\\n                          0        0  \n",
      "7       \\n\\nPlease                          0        0  \n",
      "8          \\n\\nOFF                          0        0  \n",
      "9                                           0        0  \n",
      "10                                          0        0  \n",
      "11          \\n\\n\\n                          0        1  \n",
      "12           \\nOFF                          0        0  \n",
      "13             NOT                          0        1  \n",
      "14             NOT                          0        1  \n",
      "15                                          0        0  \n",
      "16                                          0        1  \n",
      "17           \\n\\nI                          0        1  \n",
      "18             NOT                          0        0  \n",
      "19         NOT\\n\\n                          0        1  \n",
      "20      \\n\\nPlease                          0        1  \n",
      "21                                          0        0  \n",
      "22             NOT                          0        0  \n",
      "23          \\n\\n\\n                          0        0  \n",
      "24        \\n\\nYour                          0        0  \n",
      "25            \\n\\n                          0        0  \n",
      "26             NOT                          0        0  \n",
      "27             NOT                          0        0  \n",
      "28      \\n\\nPlease                          0        0  \n",
      "29        \\n\\nNote                          0        0  \n",
      "30                                          0        1  \n",
      "31           \\n\\nA                          0        0  \n",
      "32                                          0        1  \n",
      "33             NOT                          0        1  \n",
      "34           \\n\\nI                          0        0  \n",
      "35             NOT                          0        1  \n",
      "36             NOT                          0        1  \n",
      "37            \\n\\n                          0        0  \n",
      "38             OFF                          1        0  \n",
      "39             NOT                          0        0  \n",
      "40             OFF                          1        0  \n",
      "41             NOT                          0        0  \n",
      "42             NOT                          0        0  \n",
      "43        \\n\\nNote                          0        1  \n",
      "44         \\n\\nOFF                          0        1  \n",
      "45         \\n\\nOFF                          0        0  \n",
      "46                                          0        0  \n",
      "47      \\n\\nPlease                          0        1  \n",
      "48             NOT                          0        0  \n",
      "49         \\n\\nOFF                          0        1  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_df = test_range(eval_df, prompt_config_zs, prompt_examples_zs, prompt_prefix_zs, prompt_suffix_zs, pre_processing=your_pre_processing_zs, post_processing=your_post_processing_zs, model=model, debug=False)\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(results_df['corrected_model_responses']==results_df['offense'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15999999999999998"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(results_df['offense'], results_df['corrected_model_responses'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "851it [23:21,  1.65s/it]\n"
     ]
    }
   ],
   "source": [
    "test_df = get_test_set()\n",
    "results_df = test_range(test_df, prompt_config_zs, prompt_examples_zs, prompt_prefix_zs, prompt_suffix_zs, pre_processing=your_pre_processing_zs, post_processing=your_post_processing_zs, model=model, debug=False)\n",
    "results_df.to_csv('zsl_test_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7196    0.7160    0.7178       595\n",
      "           1     0.3475    0.3516    0.3495       256\n",
      "\n",
      "    accuracy                         0.6063       851\n",
      "   macro avg     0.5335    0.5338    0.5336       851\n",
      "weighted avg     0.6077    0.6063    0.6070       851\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(results_df['offense'], results_df['corrected_model_responses'], digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df = results_df.set_index(\"tweet_idx\").join(test_df.set_index('id'), lsuffix='_caller', rsuffix='_other')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = joined_df.loc[joined_df.codemixed==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6631    0.6752    0.6691       274\n",
      "           1     0.3862    0.3733    0.3797       150\n",
      "\n",
      "    accuracy                         0.5684       424\n",
      "   macro avg     0.5246    0.5243    0.5244       424\n",
      "weighted avg     0.5651    0.5684    0.5667       424\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(cm['offense_caller'], cm['corrected_model_responses'], digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "mono = joined_df.loc[joined_df.codemixed==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7700    0.7508    0.7603       321\n",
      "           1     0.2982    0.3208    0.3091       106\n",
      "\n",
      "    accuracy                         0.6440       427\n",
      "   macro avg     0.5341    0.5358    0.5347       427\n",
      "weighted avg     0.6529    0.6440    0.6483       427\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(mono['offense_caller'], mono['corrected_model_responses'], digits=4))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Few Shot Prompting (In Context Learning)\n",
    "Useful to fix output format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = get_train_df(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_example(row):\n",
    "    line1 = \"Input Tweet: \" + row['tweet_text'] + \"\\n\"\n",
    "    label = 'OFF' if row['offense']==1 else 'NOT'\n",
    "    line2 = \"Output: \" + label + \"\\n\"\n",
    "    return line1+line2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_examples_icl = \"\"\n",
    "for idx,row in train_df.iterrows():\n",
    "    ex = create_example(row)\n",
    "    prompt_examples_icl += ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_examples_icl = prompt_examples_icl + \"Input Tweet: \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_prefix_icl = \\\n",
    "'''Offensive speech focuses on the potentially hurtful effect of the tweet content on a given target. This category of text often contains offensive words such as sarcastic remarks, insults, slanders, and slurs.\n",
    "Based on above definition, classify the following Hinglish tweet into offensive speech or not. Your output should only be either \"OFF\" for offensive, or \"NOT\" for not offensive like in the examples below.\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "prompt_suffix_icl = \"Output: \"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_df = test_range(eval_df, prompt_config_zs, prompt_examples_icl, prompt_prefix_icl, prompt_suffix_icl, pre_processing=your_pre_processing_zs, post_processing=your_post_processing_zs, model=model, debug=False)\n",
    "# print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4444444444444445"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(results_df['offense'], results_df['corrected_model_responses'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "851it [28:40,  2.02s/it]\n"
     ]
    }
   ],
   "source": [
    "test_df = get_test_set()\n",
    "results_df = test_range(test_df, prompt_config_zs, prompt_examples_icl, prompt_prefix_icl, prompt_suffix_icl, pre_processing=your_pre_processing_zs, post_processing=your_post_processing_zs, model=model, debug=False)\n",
    "results_df.to_csv('icl_test_results_50ex.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9231    0.2218    0.3577       595\n",
      "           1     0.3460    0.9570    0.5083       256\n",
      "\n",
      "    accuracy                         0.4430       851\n",
      "   macro avg     0.6346    0.5894    0.4330       851\n",
      "weighted avg     0.7495    0.4430    0.4030       851\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(results_df['offense'], results_df['corrected_model_responses'], digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df = results_df.set_index(\"tweet_idx\").join(test_df.set_index('id'), lsuffix='_caller', rsuffix='_other')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = joined_df.loc[joined_df.codemixed==1]\n",
    "mono = joined_df.loc[joined_df.codemixed==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8889    0.1752    0.2927       274\n",
      "           1     0.3892    0.9600    0.5538       150\n",
      "\n",
      "    accuracy                         0.4528       424\n",
      "   macro avg     0.6390    0.5676    0.4233       424\n",
      "weighted avg     0.7121    0.4528    0.3851       424\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(cm['offense_caller'], cm['corrected_model_responses'], digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "mono = joined_df.loc[joined_df.codemixed==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9438    0.2617    0.4098       321\n",
      "           1     0.2988    0.9528    0.4550       106\n",
      "\n",
      "    accuracy                         0.4333       427\n",
      "   macro avg     0.6213    0.6073    0.4324       427\n",
      "weighted avg     0.7837    0.4333    0.4210       427\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(mono['offense_caller'], mono['corrected_model_responses'], digits=4))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chain of Thought Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "off_tweets = [\n",
    "\"Ho skta h kuch baudh to teri tarah dogle bhi nhi hote..balki bahut hmare sc ya dalit bhai hmare sath mandiro me jate h khub dharm ko mante hai snatan me viswas krte h..or kuch gaddar meem walo ka gana gate hai..wo acha h lekin jo tum kar rhe ho wo ghtiya h..jai meem bol ab\",\n",
    "\"Kab aana hai ? # Gharwapasi\",\n",
    "\"Haa...Ab Umpire Bhi IPL khelega Chutiya Sala Fixer.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "justification_off_tweets = [\"This tweet is offensive because it is insulting in nature\", \"This tweet is offensive due to the the context of Ghar Wapasi which involves religious conversions\", \"This tweet is offensive as it insults the umpire and uses cuss words.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_off_tweets = [\"I don't understand why ppl take law in hands...agar chor tha toh police complaint hone thee...bekar me moka diya jata h ke dalit exploitation ho raha h...\", \"I have of hindus crimes data agints dalit u hater.\\\n",
    "Dalit hater community.\\\n",
    "Do u have data to prove me otherwise and provide data for muslim crime against hindu\", \"#demonetisation  .. mention bigger scam than this üòÇüòÇ\",\n",
    "\"Can he himself come to court room in an himachali outfit or in an pure old adivasi dress(no dress)...\",\n",
    "\"Just like modi said corruption will end with demonetisation\\\n",
    "15 L will be in everyone's account \\\n",
    "2 million jobs every year \\\n",
    "USA will stand in line for visa etc \\\n",
    "Aap &amp; bjpeee are the two sides of lies &amp; deceit\", \"Romanticizing open defecation under heavy rain to enjoy the melancholy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "justification_non_off_tweets = [\"This tweet is not offensive as it is against lynching of individuals\", \"This tweet is not offensive as it just asks for more data\", \"This tweet is not offensive as it criticizes a government policy which is allowed in a healthy democracy\",\n",
    "                                \"This tweet is not offensive as it is in fact showcasing cultural diversity and not containing offensive language\",\n",
    "                                \"This tweet is not offensive as even though it is critical of political promises, it simply expresses a perspective on political issues.\", \"This tweet is not offensive despite the sarcasm, because it is satirical in nature without offending any group in particular\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(40)\n",
    "def create_examples(off_tweets, justification_off_tweets, non_off_tweets, justification_non_off_tweets):\n",
    "    examples = []\n",
    "\n",
    "    combined_tweets = list(zip(off_tweets, justification_off_tweets, ['OFF'] * len(off_tweets))) + \\\n",
    "                      list(zip(non_off_tweets, justification_non_off_tweets, ['NOT'] * len(non_off_tweets)))\n",
    "\n",
    "    random.shuffle(combined_tweets)\n",
    "\n",
    "    for tweet, justification, label in combined_tweets:\n",
    "        line1 = \"Input Tweet: \" + tweet + \"\\n\"\n",
    "        justification_line = \"Justification: \" + justification + \"\\n\"\n",
    "        line2 = \"Output: \" + label + \"\\n\"\n",
    "        examples.append(line1 + justification_line + line2)\n",
    "\n",
    "    return ''.join(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_examples(off_tweets, justification_off_tweets, non_off_tweets, justification_non_off_tweets):\n",
    "#     examples = \"\"\n",
    "#     for i in range(len(off_tweets)):\n",
    "#         line1 = \"Input Tweet: \" + off_tweets[i] + \"\\n\"\n",
    "#         justification_off = \"Justification: \" + justification_off_tweets[i] + \"\\n\"\n",
    "#         line2 = \"Output: \" + 'OFF' + \"\\n\"\n",
    "#         line3 = \"Input Tweet: \" + non_off_tweets[i] + \"\\n\"\n",
    "#         justification_not = \"Justification: \" + justification_non_off_tweets[i] + \"\\n\"\n",
    "#         line4 = \"Output: \" + 'NOT' + \"\\n\"\n",
    "#         set = line1 + justification_off + line2 + line3 + justification_not + line4\n",
    "#         examples+=set\n",
    "    \n",
    "#     return examples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_examples_cot = create_examples(off_tweets, justification_off_tweets, non_off_tweets, justification_non_off_tweets) + \"Input Tweet: \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Tweet: Romanticizing open defecation under heavy rain to enjoy the melancholy\n",
      "Justification: This tweet is not offensive despite the sarcasm, because it is satirical in nature without offending any group in particular\n",
      "Output: NOT\n",
      "Input Tweet: #demonetisation  .. mention bigger scam than this üòÇüòÇ\n",
      "Justification: This tweet is not offensive as it criticizes a government policy which is allowed in a healthy democracy\n",
      "Output: NOT\n",
      "Input Tweet: I don't understand why ppl take law in hands...agar chor tha toh police complaint hone thee...bekar me moka diya jata h ke dalit exploitation ho raha h...\n",
      "Justification: This tweet is not offensive as it is against lynching of individuals\n",
      "Output: NOT\n",
      "Input Tweet: I have of hindus crimes data agints dalit u hater.Dalit hater community.Do u have data to prove me otherwise and provide data for muslim crime against hindu\n",
      "Justification: This tweet is not offensive as it just asks for more data\n",
      "Output: NOT\n",
      "Input Tweet: Can he himself come to court room in an himachali outfit or in an pure old adivasi dress(no dress)...\n",
      "Justification: This tweet is not offensive as it is in fact showcasing cultural diversity and not containing offensive language\n",
      "Output: NOT\n",
      "Input Tweet: Haa...Ab Umpire Bhi IPL khelega Chutiya Sala Fixer.\n",
      "Justification: This tweet is offensive as it insults the umpire and uses cuss words.\n",
      "Output: OFF\n",
      "Input Tweet: Kab aana hai ? # Gharwapasi\n",
      "Justification: This tweet is offensive due to the the context of Ghar Wapasi which involves religious conversions\n",
      "Output: OFF\n",
      "Input Tweet: Ho skta h kuch baudh to teri tarah dogle bhi nhi hote..balki bahut hmare sc ya dalit bhai hmare sath mandiro me jate h khub dharm ko mante hai snatan me viswas krte h..or kuch gaddar meem walo ka gana gate hai..wo acha h lekin jo tum kar rhe ho wo ghtiya h..jai meem bol ab\n",
      "Justification: This tweet is offensive because it is insulting in nature\n",
      "Output: OFF\n",
      "Input Tweet: Just like modi said corruption will end with demonetisation15 L will be in everyone's account 2 million jobs every year USA will stand in line for visa etc Aap &amp; bjpeee are the two sides of lies &amp; deceit\n",
      "Justification: This tweet is not offensive as even though it is critical of political promises, it simply expresses a perspective on political issues.\n",
      "Output: NOT\n",
      "Input Tweet: \n"
     ]
    }
   ],
   "source": [
    "print(prompt_examples_cot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_prefix_cot = \\\n",
    "'''Offensive speech focuses on the potentially hurtful effect of the tweet content on a given target. This category of text often contains offensive words such as sarcastic remarks, insults, slanders, and slurs.\n",
    "Based on above definition, classify the following Hinglish tweet into offensive speech or not. Your output should be a only be either \"OFF\" for offensive, or \"NOT\" for not offensive along with a justification for your output like in the examples below.\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "prompt_suffix_cot = \"Justification: \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_string: '@user tweet'\n",
    "def your_pre_processing_cot(input_string):\n",
    "    return re.sub(r\"@user\",\"\", input_string).strip()\n",
    "\n",
    "def your_post_processing_cot(output_string):\n",
    "    # using regular expression to find the first consecutive digits in the returned string\n",
    "    if output_string.find(\"not offensive\")!=-1:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "togethercomputer/llama-2-7b\n"
     ]
    }
   ],
   "source": [
    "prompt_config_cot = {'max_tokens': 30,\n",
    "                'temperature': 0.4,\n",
    "                'top_k': 50,\n",
    "                'top_p': 0.7,\n",
    "                'repetition_penalty': 1,\n",
    "                'stop': []}\n",
    "\n",
    "model = 'togethercomputer/llama-2-70b-chat'\n",
    "print(model)\n",
    "\n",
    "eval_df = get_eval_df(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [01:31,  1.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    tweet_idx                                         tweet_text  \\\n",
      "0       75787  @user I didnt even know he is from that caste....   \n",
      "1      178470  @user Have you done any report on lakhs of und...   \n",
      "2      124492  @user You feel proud when hindu girls are murd...   \n",
      "3      192196  @user Indian Passport me Ashok chinha ke saath...   \n",
      "4      120178  @user @user Sanjay, remind me again, which par...   \n",
      "5      186613  @user Jo bharose Wale emergency lagye hai wo k...   \n",
      "6      185294  @user It's called summer weather. 1 week it's ...   \n",
      "7       75963  @user @user @user @user @user @user 1.  You as...   \n",
      "8       41859  @user ...genesis of the matter, you will mista...   \n",
      "9      213324  The national flag is a matter of pride for us....   \n",
      "10     120424  @user Jin kursiyon per abhi Kuchh log dikh rah...   \n",
      "11      80036  @user Tumhare dukane ache chal rahe he hindu M...   \n",
      "12     169159  @user @user G bilkul wo zamane gae ab sb teams...   \n",
      "13       1037  @user 2/2 You may DM me if you like. My next p...   \n",
      "14        486  Supreme Court says it will examine demonetisat...   \n",
      "15        568  @user Amazing! What about the pending cases wi...   \n",
      "16      71573  @user Swarna tak rehney do ..obc ko naraaz mat...   \n",
      "17      17528  #Delhi: Supreme Court Allows The Abortion Till...   \n",
      "18     202364  @user @user @user @user @user @user @user @use...   \n",
      "19       7698  @user @user It is... Buying something to keep ...   \n",
      "20      11449  @user If Nomkutsu was raped, will you be ok if...   \n",
      "21        850  P Chidambaram: I'm not for a petitioner who ha...   \n",
      "22      65718  @user TDS is a more serious epidemic for the D...   \n",
      "23      55291  @user @user The take-away a lot of even nomina...   \n",
      "24     120290  @user Aisi manyata hinduon me hai to ye hinduo...   \n",
      "25     192550  @user Rahul gandhi ji ko boliye modi ji se hin...   \n",
      "26      90303  @user All about you as always. People died who...   \n",
      "27       1001  @user @user @user Think beyond dog whistles an...   \n",
      "28     160012  @user @user Bhai agar yaha musalman hota to UA...   \n",
      "29        616  Chidambaram gives the English translation.\\n\\n...   \n",
      "30        668  Chidambaram: If they had to demonetise all ser...   \n",
      "31      65851  The utility of a sentinel system goes well bey...   \n",
      "32      19042  @user @user I fully support @user on equality ...   \n",
      "33      26616  Alert üåßÔ∏è\\n\\nThe situation is getting worse. Th...   \n",
      "34       1223  @user Abe chutiye ho kya be mtlb kuch bhi bhai...   \n",
      "35     164948  @user @user Kl Rahul ko hatao yaar kitna dhote...   \n",
      "36        283  @user @user @user the way we tackled covid was...   \n",
      "37      34320  The Indian Army has carried out one of the lar...   \n",
      "38      18976  Why to marry if you don't want to have a sex!?...   \n",
      "39     181788  Adhir Ranjan Choudhary on #PHRA Bill:\\nMakes s...   \n",
      "40      34348  ‚Ä¶we have Freedom I will fight in the Indian Ar...   \n",
      "41        796  Bench asks whether earlier demonetisation was ...   \n",
      "42        440  If you still think  #Demonetisation was a mast...   \n",
      "43     168888  @user Against NED also fail. Will never fire e...   \n",
      "44      49886  ISRO, Tejas and Brahmos are making me feel pro...   \n",
      "45      65821  @user You mean covid 19 vaccine linked to incr...   \n",
      "46     185207  But I do have one emergency solution that I ca...   \n",
      "47      50097  @user I love ISRO. I just have a humble reques...   \n",
      "48     133966  To the girl with the light pink hair with the ...   \n",
      "49        626  Chidambaram: 2. If not read down, section 26 (...   \n",
      "\n",
      "                                      model_responses  \\\n",
      "0   This tweet is not offensive as it is not insul...   \n",
      "1   This tweet is not offensive as it is against l...   \n",
      "2   This tweet is not offensive as it is against l...   \n",
      "3   This tweet is offensive because it is insultin...   \n",
      "4   This tweet is offensive because it is insultin...   \n",
      "5   This tweet is not offensive as it is critical ...   \n",
      "6   This tweet is not offensive as it is sarcastic...   \n",
      "7   This tweet is not offensive as it is critical ...   \n",
      "8   This tweet is offensive as it insults the Nige...   \n",
      "9   This tweet is not offensive as it is critical ...   \n",
      "10  This tweet is offensive as it insults the umpi...   \n",
      "11  This tweet is not offensive as it is against l...   \n",
      "12  This tweet is not offensive as it is in fact s...   \n",
      "13  This tweet is not offensive as it is satirical...   \n",
      "14  This tweet is not offensive as it is a critica...   \n",
      "15  This tweet is not offensive as it is critical ...   \n",
      "16  This tweet is offensive as it is insulting in ...   \n",
      "17  This tweet is not offensive as it is a legal d...   \n",
      "18  This tweet is not offensive as it is a sarcast...   \n",
      "19  This tweet is not offensive as it is against t...   \n",
      "20  This tweet is not offensive as it is in fact s...   \n",
      "21  This tweet is not offensive as it is critical ...   \n",
      "22  This tweet is not offensive as it is a satiric...   \n",
      "23  This tweet is not offensive as it is a satiric...   \n",
      "24  This tweet is offensive as it insults the Hind...   \n",
      "25  This tweet is not offensive as it is satirical...   \n",
      "26  This tweet is offensive because it is insultin...   \n",
      "27  This tweet is not offensive as it is a critici...   \n",
      "28  This tweet is not offensive as it is against t...   \n",
      "29  This tweet is not offensive as it is in fact s...   \n",
      "30  This tweet is not offensive as it is a critici...   \n",
      "31  This tweet is not offensive as it is simply a ...   \n",
      "32  This tweet is not offensive as it is critical ...   \n",
      "33  This tweet is not offensive as it is not insul...   \n",
      "34  This tweet is offensive as it is insulting in ...   \n",
      "35  This tweet is not offensive as it is not insul...   \n",
      "36  This tweet is not offensive as it is satirical...   \n",
      "37  This tweet is not offensive as it is a factual...   \n",
      "38  This tweet is not offensive as it is critical ...   \n",
      "39  This tweet is not offensive as it is not insul...   \n",
      "40  This tweet is not offensive as it is a patriot...   \n",
      "41  This tweet is not offensive as it is a satiric...   \n",
      "42  This tweet is not offensive as it is satirical...   \n",
      "43  This tweet is not offensive as it is against N...   \n",
      "44  This tweet is not offensive as it is in fact s...   \n",
      "45  This tweet is not offensive as it is critical ...   \n",
      "46  This tweet is not offensive as it is a satiric...   \n",
      "47  This tweet is not offensive as it is a humorou...   \n",
      "48  This tweet is not offensive as it is a satiric...   \n",
      "49  This tweet is not offensive as it is critical ...   \n",
      "\n",
      "    corrected_model_responses  offense  \n",
      "0                           0        0  \n",
      "1                           0        0  \n",
      "2                           0        1  \n",
      "3                           1        0  \n",
      "4                           1        1  \n",
      "5                           0        1  \n",
      "6                           0        0  \n",
      "7                           0        0  \n",
      "8                           1        0  \n",
      "9                           0        1  \n",
      "10                          1        1  \n",
      "11                          0        0  \n",
      "12                          0        0  \n",
      "13                          0        0  \n",
      "14                          0        0  \n",
      "15                          0        1  \n",
      "16                          1        0  \n",
      "17                          0        0  \n",
      "18                          0        0  \n",
      "19                          0        0  \n",
      "20                          0        1  \n",
      "21                          0        0  \n",
      "22                          0        0  \n",
      "23                          0        0  \n",
      "24                          1        1  \n",
      "25                          0        0  \n",
      "26                          0        1  \n",
      "27                          0        1  \n",
      "28                          0        0  \n",
      "29                          0        0  \n",
      "30                          0        0  \n",
      "31                          0        0  \n",
      "32                          0        0  \n",
      "33                          0        0  \n",
      "34                          1        1  \n",
      "35                          0        0  \n",
      "36                          0        0  \n",
      "37                          0        0  \n",
      "38                          0        0  \n",
      "39                          0        0  \n",
      "40                          0        0  \n",
      "41                          0        0  \n",
      "42                          0        1  \n",
      "43                          0        0  \n",
      "44                          0        0  \n",
      "45                          0        0  \n",
      "46                          0        0  \n",
      "47                          0        0  \n",
      "48                          0        0  \n",
      "49                          0        0  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_df = test_range(eval_df, prompt_config_cot, prompt_examples_cot, prompt_prefix_cot, prompt_suffix_cot, pre_processing=your_pre_processing_cot, post_processing=your_post_processing_cot, model=model, debug=False)\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv('error_analysis.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df['corrected_model_responses'] = results_df['model_responses'].apply(your_post_processing_cot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4210526315789474"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(results_df['offense'], results_df['corrected_model_responses'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.78      0.77       595\n",
      "           1       0.47      0.45      0.46       256\n",
      "\n",
      "    accuracy                           0.68       851\n",
      "   macro avg       0.62      0.61      0.61       851\n",
      "weighted avg       0.68      0.68      0.68       851\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(results_df['offense'], results_df['corrected_model_responses']))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Set Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = get_test_set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "851it [25:45,  1.82s/it]\n"
     ]
    }
   ],
   "source": [
    "results_df = test_range(test_df, prompt_config_cot, prompt_examples_cot, prompt_prefix_cot, prompt_suffix_cot, pre_processing=your_pre_processing_cot, post_processing=your_post_processing_cot, model=model, debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df['corrected_model_responses'] = results_df['model_responses'].apply(your_post_processing_cot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.75      0.80       595\n",
      "           1       0.54      0.69      0.61       256\n",
      "\n",
      "    accuracy                           0.73       851\n",
      "   macro avg       0.70      0.72      0.70       851\n",
      "weighted avg       0.76      0.73      0.74       851\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(results_df['offense'], results_df['corrected_model_responses']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv('test_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "851it [29:50,  2.10s/it]\n"
     ]
    }
   ],
   "source": [
    "results_df = test_range(test_df, prompt_config_cot, prompt_examples_cot, prompt_prefix_cot, prompt_suffix_cot, pre_processing=your_pre_processing_cot, post_processing=your_post_processing_cot, model=model, debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df['corrected_model_responses'] = results_df['model_responses'].apply(your_post_processing_cot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.read_csv('test_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8498    0.7513    0.7975       595\n",
      "           1     0.5446    0.6914    0.6093       256\n",
      "\n",
      "    accuracy                         0.7333       851\n",
      "   macro avg     0.6972    0.7213    0.7034       851\n",
      "weighted avg     0.7580    0.7333    0.7409       851\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(results_df['offense'], results_df['corrected_model_responses'], digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df = results_df.set_index(\"tweet_idx\").join(test_df.set_index('id'), lsuffix='_caller', rsuffix='_other')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = joined_df.loc[joined_df.codemixed==1]\n",
    "mono = joined_df.loc[joined_df.codemixed==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8715    0.7819    0.8243       321\n",
      "           1     0.4964    0.6509    0.5633       106\n",
      "\n",
      "    accuracy                         0.7494       427\n",
      "   macro avg     0.6840    0.7164    0.6938       427\n",
      "weighted avg     0.7784    0.7494    0.7595       427\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(mono['offense_caller'], mono['corrected_model_responses'], digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8235    0.7153    0.7656       274\n",
      "           1     0.5806    0.7200    0.6429       150\n",
      "\n",
      "    accuracy                         0.7170       424\n",
      "   macro avg     0.7021    0.7177    0.7042       424\n",
      "weighted avg     0.7376    0.7170    0.7222       424\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(cm['offense_caller'], cm['corrected_model_responses'], digits=4))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OOD Set Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ood_set():\n",
    "    ood_df = pd.read_csv('./data/splits/cm_hate_combined.csv')\n",
    "    return ood_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "ood_df = get_ood_set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "ood_df['tweet_text'] = ood_df['tweet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'togethercomputer/llama-2-70b'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "641it [23:39,  2.21s/it]\n"
     ]
    }
   ],
   "source": [
    "results_df = test_range(ood_df, prompt_config_cot, prompt_examples_cot, prompt_prefix_cot, prompt_suffix_cot, pre_processing=your_pre_processing_cot, post_processing=your_post_processing_cot, model=model, debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df['corrected_model_responses'] = results_df['model_responses'].apply(your_post_processing_cot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.45      0.60       362\n",
      "           1       0.56      0.92      0.70       279\n",
      "\n",
      "    accuracy                           0.66       641\n",
      "   macro avg       0.72      0.69      0.65       641\n",
      "weighted avg       0.74      0.66      0.64       641\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(results_df['offense'], results_df['corrected_model_responses']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "641it [22:11,  2.08s/it]\n"
     ]
    }
   ],
   "source": [
    "results_df = test_range(ood_df, prompt_config_cot, prompt_examples_cot, prompt_prefix_cot, prompt_suffix_cot, pre_processing=your_pre_processing_cot, post_processing=your_post_processing_cot, model=model, debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df['corrected_model_responses'] = results_df['model_responses'].apply(your_post_processing_cot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv('ood_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.read_csv('ood_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9179    0.3398    0.4960       362\n",
      "           1     0.5286    0.9606    0.6819       279\n",
      "\n",
      "    accuracy                         0.6100       641\n",
      "   macro avg     0.7233    0.6502    0.5890       641\n",
      "weighted avg     0.7485    0.6100    0.5769       641\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(results_df['offense'], results_df['corrected_model_responses'], digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df = results_df.set_index('tweet_idx').join(ood_df.set_index('id'), lsuffix='_caller', rsuffix='_other')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgn = joined_df.loc[joined_df['domain']=='religion']\n",
    "gen = joined_df.loc[joined_df['domain']=='gender']\n",
    "ori = joined_df.loc[joined_df['domain']=='orientation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6421    0.7821    0.7052       156\n",
      "           1     0.4925    0.3267    0.3929       101\n",
      "\n",
      "    accuracy                         0.6031       257\n",
      "   macro avg     0.5673    0.5544    0.5490       257\n",
      "weighted avg     0.5833    0.6031    0.5825       257\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(rgn['offense_caller'], rgn['corrected_model_responses'], digits=4))\n",
    "print(classification_report(gen['offense_caller'], gen['corrected_model_responses'], digits=4))\n",
    "print(classification_report(ori['offense_caller'], ori['corrected_model_responses'], digits=4))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ZSL OOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "641it [17:16,  1.62s/it]\n"
     ]
    }
   ],
   "source": [
    "results_df = test_range(ood_df, prompt_config_zs, prompt_examples_zs, prompt_prefix_zs, prompt_suffix_zs, pre_processing=your_pre_processing_zs, post_processing=your_post_processing_zs, model=model, debug=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv('zsl_ood_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df = results_df.set_index('tweet_idx').join(ood_df.set_index('id'), lsuffix='_caller', rsuffix='_other')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgn = joined_df.loc[joined_df['domain']=='religion']\n",
    "gen = joined_df.loc[joined_df['domain']=='gender']\n",
    "ori = joined_df.loc[joined_df['domain']=='orientation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6421    0.7821    0.7052       156\n",
      "           1     0.4925    0.3267    0.3929       101\n",
      "\n",
      "    accuracy                         0.6031       257\n",
      "   macro avg     0.5673    0.5544    0.5490       257\n",
      "weighted avg     0.5833    0.6031    0.5825       257\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5476    0.7616    0.6371       151\n",
      "           1     0.4706    0.2520    0.3282       127\n",
      "\n",
      "    accuracy                         0.5288       278\n",
      "   macro avg     0.5091    0.5068    0.4827       278\n",
      "weighted avg     0.5124    0.5288    0.4960       278\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.4872    0.6909    0.5714        55\n",
      "           1     0.3929    0.2157    0.2785        51\n",
      "\n",
      "    accuracy                         0.4623       106\n",
      "   macro avg     0.4400    0.4533    0.4250       106\n",
      "weighted avg     0.4418    0.4623    0.4305       106\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5753    0.7597    0.6548       362\n",
      "           1     0.4663    0.2724    0.3439       279\n",
      "\n",
      "    accuracy                         0.5476       641\n",
      "   macro avg     0.5208    0.5160    0.4993       641\n",
      "weighted avg     0.5278    0.5476    0.5195       641\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(rgn['offense_caller'], rgn['corrected_model_responses'], digits=4))\n",
    "print(classification_report(gen['offense_caller'], gen['corrected_model_responses'], digits=4))\n",
    "print(classification_report(ori['offense_caller'], ori['corrected_model_responses'], digits=4))\n",
    "print(classification_report(joined_df['offense_caller'], joined_df['corrected_model_responses'], digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ICL OOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "641it [20:53,  1.95s/it]\n"
     ]
    }
   ],
   "source": [
    "results_df = test_range(ood_df, prompt_config_zs, prompt_examples_icl, prompt_prefix_icl, prompt_suffix_icl, pre_processing=your_pre_processing_zs, post_processing=your_post_processing_zs, model=model, debug=False)\n",
    "results_df.to_csv('icl_ood_results_50ex.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df = results_df.set_index('tweet_idx').join(ood_df.set_index('id'), lsuffix='_caller', rsuffix='_other')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgn = joined_df.loc[joined_df['domain']=='religion']\n",
    "gen = joined_df.loc[joined_df['domain']=='gender']\n",
    "ori = joined_df.loc[joined_df['domain']=='orientation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    0.0769    0.1429       156\n",
      "           1     0.4122    1.0000    0.5838       101\n",
      "\n",
      "    accuracy                         0.4397       257\n",
      "   macro avg     0.7061    0.5385    0.3633       257\n",
      "weighted avg     0.7690    0.4397    0.3162       257\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8000    0.0530    0.0994       151\n",
      "           1     0.4664    0.9843    0.6329       127\n",
      "\n",
      "    accuracy                         0.4784       278\n",
      "   macro avg     0.6332    0.5186    0.3661       278\n",
      "weighted avg     0.6476    0.4784    0.3431       278\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000        55\n",
      "           1     0.4811    1.0000    0.6497        51\n",
      "\n",
      "    accuracy                         0.4811       106\n",
      "   macro avg     0.2406    0.5000    0.3248       106\n",
      "weighted avg     0.2315    0.4811    0.3126       106\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9091    0.0552    0.1042       362\n",
      "           1     0.4475    0.9928    0.6169       279\n",
      "\n",
      "    accuracy                         0.4633       641\n",
      "   macro avg     0.6783    0.5240    0.3605       641\n",
      "weighted avg     0.7082    0.4633    0.3273       641\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shikharrastogi/opt/anaconda3/envs/2590-hw4/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/shikharrastogi/opt/anaconda3/envs/2590-hw4/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/shikharrastogi/opt/anaconda3/envs/2590-hw4/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(rgn['offense_caller'], rgn['corrected_model_responses'], digits=4))\n",
    "print(classification_report(gen['offense_caller'], gen['corrected_model_responses'], digits=4))\n",
    "print(classification_report(ori['offense_caller'], ori['corrected_model_responses'], digits=4))\n",
    "print(classification_report(joined_df['offense_caller'], joined_df['corrected_model_responses'], digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "2590-hw4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
